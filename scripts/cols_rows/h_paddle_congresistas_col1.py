import json
import os
import re
from collections import defaultdict
from pathlib import Path

import pandas as pd
from paddleocr import PaddleOCR
from tqdm import tqdm

# Directorios de entrada y salida
TIPO = "paddle_congresistas"
COLUMN_NAME = "columna_1"
DIR_NAMES_CSV = "/home/nahumfg/GithubProjects/parliament-voting-records/data/col_rows/dir_names.csv"
PARQUET = "/home/nahumfg/GithubProjects/parliament-voting-records/data/col_rows/congresistas_images.parquet"
OUTPUT_DIR = (
    f"/home/nahumfg/GithubProjects/parliament-voting-records/data/col_rows/{TIPO}_{COLUMN_NAME}"
)

# Configuraci√≥n de PaddleOCR
USE_GPU = True  # Cambiar a False si no tienes GPU con CUDA
LANG = "es"  # Espa√±ol
BATCH_SIZE = 128  # N√∫mero de im√°genes a procesar en lote (ajustar seg√∫n VRAM disponible)

# Caracteres permitidos para el reconocimiento
ALLOWED_CHARS = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë,; "

# Variable global para el reader de PaddleOCR (se inicializa una sola vez)
reader = None


def natural_sort_key(text):
    """
    Clave para ordenamiento natural (fil_1.png, fil_2.png, ..., fil_10.png)
    """

    def atoi(text):
        return int(text) if text.isdigit() else text

    return [atoi(c) for c in re.split(r"(\d+)", text)]


def extract_document_id_and_page(dir_name):
    """
    Extrae el UUID del documento y el n√∫mero de p√°gina del dir_name.
    Ejemplo: '000058a7-4618-53af-82f8-13266eef3ace_page003_' ->
             ('000058a7-4618-53af-82f8-13266eef3ace', 'page003')
    """
    # Patr√≥n: UUID_pageXXX_
    match = re.match(r"^([a-f0-9\-]+)_(page\d+)_$", dir_name)
    if match:
        return match.group(1), match.group(2)
    return None, None


def initialize_reader():
    """
    Inicializa el reader de PaddleOCR una sola vez.
    Esto es importante porque la inicializaci√≥n carga los modelos en GPU/memoria.
    """
    global reader
    if reader is None:
        print(f"\nüîß Inicializando PaddleOCR...")
        print(f"   - GPU habilitada: {USE_GPU}")
        print(f"   - Idioma: {LANG}")
        print(f"   - Caracteres permitidos: {len(ALLOWED_CHARS)} caracteres")
        reader = PaddleOCR(
            use_angle_cls=True,
            lang=LANG,
            use_gpu=USE_GPU,
            show_log=False,
            rec_char_whitelist=ALLOWED_CHARS,  # Limitar caracteres a reconocer
        )
        print("‚úì PaddleOCR inicializado correctamente")
    return reader


def apply_ocr_to_image(image_path, ocr_reader):
    """
    Aplica PaddleOCR a una imagen y retorna el texto extra√≠do.
    Retorna string vac√≠o si la imagen no existe o hay error.

    Args:
        image_path: Ruta a la imagen
        ocr_reader: Instancia de PaddleOCR
    """
    try:
        if not os.path.exists(image_path):
            return ""

        # Aplicar OCR con PaddleOCR
        # ocr() retorna una lista de resultados por p√°gina
        # Cada resultado es una lista de l√≠neas detectadas
        # Cada l√≠nea es: [bbox, (text, confidence)]
        result = ocr_reader.ocr(image_path, cls=True)

        if result is None or len(result) == 0 or result[0] is None:
            return ""

        # Extraer todos los textos detectados
        texts = []
        for line in result[0]:
            if line:
                text = line[1][0]  # line[1] es (text, confidence), line[1][0] es el texto
                if text.strip():  # Solo agregar si hay texto
                    texts.append(text)

        # Unir todos los textos detectados en una sola l√≠nea (con espacios)
        return " ".join(texts).strip()
    except Exception as e:
        return ""


def process_images_in_batches(image_paths, ocr_reader, batch_size):
    """
    Procesa m√∫ltiples im√°genes en lotes para mayor eficiencia.

    Args:
        image_paths: Lista de rutas de im√°genes
        ocr_reader: Instancia de PaddleOCR
        batch_size: Tama√±o del lote

    Returns:
        Lista de textos extra√≠dos en el mismo orden que image_paths
    """
    results = []

    for i in range(0, len(image_paths), batch_size):
        batch = image_paths[i : i + batch_size]

        for img_path in batch:
            text = apply_ocr_to_image(img_path, ocr_reader)
            results.append(text)

    return results


def process_images():
    """
    Procesa las im√°genes:
    1. Lee dir_names.csv
    2. Filtra congresistas_images.parquet
    3. Aplica OCR a cada imagen usando PaddleOCR con GPU
    4. PaddleOCR reconoce solo: letras (a-z, A-Z), acentos, √±, comas, punto y coma y espacios
    5. Agrupa resultados por documento y p√°gina
    6. Guarda JSONs
    """
    print("=" * 70)
    print("üöÄ INICIANDO PROCESAMIENTO DE OCR EN COLUMNAS (PaddleOCR + GPU)")
    print("=" * 70)

    # Inicializar PaddleOCR
    ocr_reader = initialize_reader()

    # 1. Leer dir_names.csv
    print("\nüìÇ 1. Leyendo dir_names.csv...")
    if not os.path.exists(DIR_NAMES_CSV):
        print(f"‚ùå ERROR: No se encuentra {DIR_NAMES_CSV}")
        return

    dir_names_df = pd.read_csv(DIR_NAMES_CSV)
    dir_names_set = set(dir_names_df["dir_name"].tolist())
    print(f"‚úì Se encontraron {len(dir_names_set)} dir_names √∫nicos")

    # 2. Leer y filtrar parquet
    print("\nüìÇ 2. Leyendo y filtrando congresistas_images.parquet...")
    if not os.path.exists(PARQUET):
        print(f"‚ùå ERROR: No se encuentra {PARQUET}")
        return

    df = pd.read_parquet(PARQUET)
    print(f"‚úì Archivo parquet cargado: {len(df)} registros totales")

    # Filtrar por dir_names y column=COLUMN_NAME
    df_filtered = df[df["dir_name"].isin(dir_names_set) & (df["column"] == COLUMN_NAME)]
    print(f"‚úì Despu√©s de filtrar por dir_names y {COLUMN_NAME}: {len(df_filtered)} registros")

    if len(df_filtered) == 0:
        print("‚ö†Ô∏è  No hay registros para procesar despu√©s de filtrar")
        return

    # 3. Crear directorio de salida
    print(f"\nüìÅ 3. Creando directorio de salida...")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"‚úì Directorio de salida: {OUTPUT_DIR}")

    # 4. Agrupar por documento
    print("\nüîç 4. Agrupando datos por documento...")
    documents = defaultdict(lambda: defaultdict(list))

    # Agrupar las filas por documento y p√°gina
    for _, row in df_filtered.iterrows():
        dir_name = row["dir_name"]
        image_path = row["image_path"]
        image_name = row["image_name"]

        doc_id, page = extract_document_id_and_page(dir_name)
        if doc_id and page:
            documents[doc_id][page].append((image_path, image_name))

    print(f"‚úì Se encontraron {len(documents)} documentos √∫nicos")
    print(f"‚úì Total de p√°ginas a procesar: {sum(len(pages) for pages in documents.values())}")

    # 5. Procesar cada documento
    print("\nüî¨ 5. Procesando OCR en im√°genes con PaddleOCR...")
    print(f"‚öôÔ∏è  Procesamiento en GPU (batch_size={BATCH_SIZE})")
    print(
        f"üî§ PaddleOCR configurado para reconocer solo: letras (a-z, A-Z), acentos, √±, comas y punto y coma"
    )
    total_images = len(df_filtered)

    with tqdm(total=total_images, desc="Procesando im√°genes", unit="img") as pbar:
        for doc_id, pages in documents.items():
            doc_result = {}

            # Procesar cada p√°gina del documento
            for page, images in sorted(pages.items()):
                # Ordenar im√°genes por nombre usando ordenamiento natural
                images_sorted = sorted(images, key=lambda x: natural_sort_key(x[1]))

                # Extraer solo las rutas de im√°genes
                image_paths = [img_path for img_path, _ in images_sorted]

                # Procesar im√°genes en lotes
                page_texts = []
                for img_path in image_paths:
                    text = apply_ocr_to_image(img_path, ocr_reader)
                    page_texts.append(text)
                    pbar.update(1)

                doc_result[page] = page_texts

            # Guardar JSON del documento
            json_filename = f"{doc_id}.json"
            json_path = os.path.join(OUTPUT_DIR, json_filename)

            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(doc_result, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ ¬°Proceso completado!")
    print(f"üìä Resumen:")
    print(f"   - Documentos procesados: {len(documents)}")
    print(f"   - Im√°genes procesadas: {total_images}")
    print(f"   - JSONs guardados en: {OUTPUT_DIR}")
    print("=" * 70)


def main():
    process_images()


if __name__ == "__main__":
    main()
